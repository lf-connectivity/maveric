{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13f4253c",
   "metadata": {},
   "source": [
    "# RADP RF Digital Twin + CCO Demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4055a0fb",
   "metadata": {},
   "source": [
    "# Prerequisite\n",
    "\n",
    "### Ensure to install ffmpeg on your machine and create .env\n",
    "\n",
    "Provide the executable ffmpeg file path in .env file.\n",
    "\n",
    "Create .env file in root folder of repo and add below to env\n",
    "\n",
    "`FFMPEG_PATH=\"/path_to_ffmpeg/ffmpeg\"`\n",
    "\n",
    "\n",
    "### Sample data set\n",
    "\n",
    "Unpack the sample data set present at `notebooks/data/sim_data.zip` under `notebooks/data/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbbaff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(f\"{Path().absolute().parent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf7d049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.ndimage import correlate\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from radp_library import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f692e7fb",
   "metadata": {},
   "source": [
    "## Using pregenerated data stored locally\n",
    "Currently the data is stored under notebooks\n",
    "\n",
    "/data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de49cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = f\"{Path().absolute()}\"\n",
    "BUCKET_PATH = f\"{WORKING_DIR}/data\"\n",
    "SIM_DATA_PATH = \"sim_data/3cell\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6eaf84",
   "metadata": {},
   "source": [
    "## Bayesian digital twin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ad26d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide list of folder name under which the pregenerated data is stored\n",
    "sim_idx_folders = ['sim_001', 'sim_002', 'sim_003', 'sim_004', 'sim_005']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c32129",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "p_train_maxiter_dict = {\n",
    "        10: [1, 2],\n",
    "        40: [10]\n",
    "}\n",
    "p_test = 100\n",
    "\n",
    "pred_rsrp_list = []\n",
    "MAE_list = []\n",
    "Percentile85Error_list = []\n",
    "p_train_list = []\n",
    "maxiter_list = []\n",
    "\n",
    "\n",
    "for p_train in p_train_maxiter_dict.keys():\n",
    "    for maxiter in p_train_maxiter_dict[p_train]:\n",
    "        logging.info(f\"\\n\\nMAXITER = {maxiter}, p_train={p_train}\\n\")\n",
    "        _, site_config_df, test_data, loss_vs_iter, lons, lats, true_rsrp, pred_rsrp, MAE, Percentile85Error = bdt(\n",
    "            bucket_path=BUCKET_PATH,\n",
    "            sim_data_path=SIM_DATA_PATH,\n",
    "            p_train=p_train,\n",
    "            p_test=p_test,\n",
    "            maxiter=maxiter,\n",
    "            sim_idx_folders=sim_idx_folders,\n",
    "            test_idx=2,\n",
    "            plot_loss_vs_iter=True,\n",
    "            choose_strongest_samples_percell=False,\n",
    "            filter_out_samples_dbm_threshold=-70,\n",
    "            filter_out_samples_kms_threshold=0.65,\n",
    "            # track_sampling=True,\n",
    "            # num_UEs=2,\n",
    "            # ticks=100,\n",
    "        )\n",
    "        p_train_list.append(p_train)\n",
    "        maxiter_list.append(maxiter)\n",
    "        pred_rsrp_list.append(pred_rsrp)\n",
    "        MAE_list.append(MAE)\n",
    "        Percentile85Error_list.append(Percentile85Error)\n",
    "\n",
    "df_results = pd.DataFrame(\n",
    "    {\n",
    "        \"pred_rsrp_list\": pred_rsrp_list,\n",
    "        \"MAE_list\": MAE_list,\n",
    "        \"Percentile85Error_list\": Percentile85Error_list,\n",
    "        \"maxiter_list\": maxiter_list,\n",
    "        \"p_train_list\": p_train_list,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8de2ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917334bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2draster(lats ,lons, vals, z):\n",
    "    min_lon_tile, min_lat_tile = lon_lat_to_bing_tile(min(lons), min(lats), level=z)\n",
    "    max_lon_tile, max_lat_tile = lon_lat_to_bing_tile(max(lons), max(lats), level=z)\n",
    "\n",
    "    val_dict = {}\n",
    "    for lon, lat, val in zip(lons, lats, vals):\n",
    "        lon_idx, lat_idx = lon_lat_to_bing_tile(lon, lat, level=z)\n",
    "        row_idx = lat_idx - max_lat_tile\n",
    "        col_idx = lon_idx - min_lon_tile\n",
    "        if row_idx not in val_dict:\n",
    "            val_dict[row_idx] = {}\n",
    "        if col_idx not in val_dict[row_idx]:\n",
    "            val_dict[row_idx][col_idx] = []\n",
    "        val_dict[row_idx][col_idx].append(val)\n",
    "\n",
    "    num_cols = max_lon_tile - min_lon_tile + 1\n",
    "    num_rows = min_lat_tile - max_lat_tile + 1\n",
    "    raster = np.empty((num_rows, num_cols))\n",
    "    raster.fill(min(true_rsrp))\n",
    "    for lat_idx in val_dict.keys():\n",
    "        for lon_idx in val_dict[lat_idx].keys():\n",
    "            if val_dict[lat_idx][lon_idx] == []:\n",
    "                raster[lat_idx][lon_idx] = min(true_rsrp)\n",
    "            else:\n",
    "                raster[lat_idx][lon_idx] = np.average(val_dict[lat_idx][lon_idx])\n",
    "\n",
    "    return raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b6f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(\n",
    "    {\n",
    "        \"pred_rsrp_list\": pred_rsrp_list,\n",
    "        \"MAE_list\": MAE_list,\n",
    "        \"Percentile85Error_list\": Percentile85Error_list,\n",
    "        \"maxiter_list\": maxiter_list,\n",
    "        \"p_train_list\": p_train_list,\n",
    "    }\n",
    ")\n",
    "\n",
    "df_results[\"pearson_corr\"] = df_results.apply(\n",
    "    lambda x: stats.pearsonr(true_rsrp, x.pred_rsrp_list)[0], axis=1\n",
    ")\n",
    "\n",
    "perc = 99\n",
    "df_results[\"tail_error\"] = df_results.apply(\n",
    "    lambda x: np.percentile(abs(true_rsrp - x.pred_rsrp_list), perc), axis=1\n",
    ")\n",
    "\n",
    "\n",
    "lambda_corr = 0.8\n",
    "\n",
    "df_results[\"MAE_list_normalized_inverted\"] = 1 - normalize_data(df_results[['MAE_list']])\n",
    "\n",
    "df_results[\"tail_error_normalized_inverted\"] = 1 - normalize_data(df_results[['tail_error']])\n",
    "\n",
    "df_results[\"pearson_corr_normalized\"] = normalize_data(df_results[['pearson_corr']])\n",
    "\n",
    "df_results[\"Percentile85Error_list_normalized_inverted\"] = 1 - normalize_data(df_results[['Percentile85Error_list']])\n",
    "\n",
    "df_results[\"pearson_MAE_inverted_normalized_mean\"] = df_results[['pearson_corr_normalized', 'MAE_list_normalized_inverted']].mean(axis=1)\n",
    "\n",
    "df_results[\"pearson_Percentile85Error_inverted_normalized_mean\"] = df_results[['pearson_corr_normalized','Percentile85Error_list_normalized_inverted']].mul(\n",
    "    (lambda_corr, 1 -lambda_corr)\n",
    ").sum(1)\n",
    "\n",
    "df_results[\"pearson_tail_error_inverted_normalized_mean\"] = df_results[['pearson_corr_normalized', 'tail_error_normalized_inverted']].mean(axis=1)\n",
    "\n",
    "\n",
    "df_results[\"variance_error\"] = df_results.apply(\n",
    "    lambda x: np.var(true_rsrp - x.pred_rsrp_list), axis=1\n",
    ")\n",
    "\n",
    "df_results_sorted = df_results\n",
    "\n",
    "\n",
    "anim, fig = animate_predictions(\n",
    "    lats,\n",
    "    lons,\n",
    "    true_rsrp,\n",
    "    df_results_sorted.pred_rsrp_list.to_list(),\n",
    "    df_results_sorted.MAE_list.to_list(),\n",
    "    df_results_sorted.Percentile85Error_list.to_list(),\n",
    "    df_results_sorted.maxiter_list.to_list(),\n",
    "    df_results_sorted.p_train_list.to_list(),\n",
    "    \"/tmp/animation_digital_twin_larger_network_iter_scanning_v4.mp4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d265ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_true = get_2draster(lats, lons, df_results.pred_rsrp_list[2], 19)\n",
    "weights = [[0, 1, 0],\n",
    "           [1, 1, 1],\n",
    "           [0, 1, 0]]\n",
    "raster_true_smoothed = correlate(raster_true, weights, mode='nearest')\n",
    "plt.imshow(raster_true_smoothed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518d24ca",
   "metadata": {},
   "source": [
    "plt.plot(df_results[\"ssim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2718dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(abs(true_rsrp - df_results_sorted.pred_rsrp_list.iloc[2]))\n",
    "print(\"Error = \", df_results_sorted.MAE_list.iloc[2])\n",
    "print(\"Correlation = \", df_results_sorted.pearson_corr.iloc[2])\n",
    "print(\"25th percentile = \", np.percentile(abs(true_rsrp - df_results_sorted.pred_rsrp_list.iloc[2]), 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfda05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(abs(true_rsrp - df_results_sorted.pred_rsrp_list.iloc[2]))\n",
    "print(\"Error = \", df_results_sorted.MAE_list.iloc[2])\n",
    "print(\"Correlation = \", df_results_sorted.pearson_corr.iloc[2])\n",
    "print(\"25th percentile = \", np.percentile(abs(true_rsrp - df_results_sorted.pred_rsrp_list.iloc[2]), 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd274469",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_sorted.MAE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ddc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxiters=[38]\n",
    "p_train_list=[40]\n",
    "_, site_config_df, test_data, loss_vs_iter, lons, lats, true_rsrp, pred_rsrp, MAE, Percentile85Error = bdt(\n",
    "    bucket_path=BUCKET_PATH,\n",
    "    sim_data_path=SIM_DATA_PATH,\n",
    "    p_train=p_train_list[0],\n",
    "    p_test=100,\n",
    "    maxiter=maxiters[0],\n",
    "    sim_idx_folders=sim_idx_folders,\n",
    "    test_idx=2,\n",
    "    plot_loss_vs_iter=True,\n",
    "    choose_strongest_samples_percell=False,\n",
    "    filter_out_samples_dbm_threshold=-70,\n",
    "    filter_out_samples_kms_threshold=0.65,\n",
    ")\n",
    "animate_predictions(\n",
    "    lats,\n",
    "    lons,\n",
    "    true_rsrp,\n",
    "    [pred_rsrp],\n",
    "    [MAE],\n",
    "    [Percentile85Error],\n",
    "    maxiters,\n",
    "    p_train_list,\n",
    "    \"/tmp/animation_digital_twin_larger_network_iter_scanning_v5.mp4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d22cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_sorted.pearson_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00afefe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(\n",
    "    {\n",
    "        \"loc_x\": [1.1, 2.3, 4.5],\n",
    "        \"loc_y\": [-7.005, 68, 2.22],\n",
    "        \"pred_rsrp\": [10, 10, 10],\n",
    "        \"cell_rxpwr_dbm\": [12.0, 12.0, 12.0],\n",
    "    }\n",
    ")\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        \"loc_x\": [4.5, 1.1, 70.004],\n",
    "        \"loc_y\": [2.22, -7.005, 2.22],\n",
    "        \"pred_rsrp\": [20, 20, 20],\n",
    "        \"cell_rxpwr_dbm\": [12.0000, 12.00001, 12.00001],\n",
    "    }\n",
    ")\n",
    "\n",
    "pd.concat([df1, df2]).groupby([\"loc_x\", \"loc_y\"], as_index=False)[[\"pred_rsrp\", \"cell_rxpwr_dbm\"]].max()\n",
    "\n",
    "print(df1.apply(lon_lat_to_bing_tile_df_row, level=20, axis=1))\n",
    "print(df1.apply(lon_lat_to_bing_tile_df_row, level=20, axis=1).apply(bing_tile_to_center_df_row, level=20, axis=1))\n",
    "print(\n",
    "    df1.apply(lon_lat_to_bing_tile_df_row, level=20, axis=1)\n",
    "    .apply(bing_tile_to_center_df_row, level=20, axis=1)\n",
    "    .apply(lon_lat_to_bing_tile_df_row, level=20, axis=1)\n",
    ")\n",
    "print(\n",
    "    df1.apply(lon_lat_to_bing_tile_df_row, level=20, axis=1)\n",
    "    .apply(bing_tile_to_center_df_row, level=20, axis=1)\n",
    "    .apply(lon_lat_to_bing_tile_df_row, level=20, axis=1)\n",
    "    .apply(bing_tile_to_center_df_row, level=20, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5136b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = test_data[1][\"loc_x\"].values\n",
    "lats = test_data[1][\"loc_y\"].values\n",
    "\n",
    "step = SRTM_STEP * 1.1\n",
    "\n",
    "min_lon = min(lons)\n",
    "max_lon = max(lons)\n",
    "min_lat = min(lats)\n",
    "max_lat = max(lats)\n",
    "lon_dims = math.ceil((max_lon - min_lon) / step)\n",
    "lat_dims = math.ceil((max_lat - min_lat) / step)\n",
    "\n",
    "rf_raster = np.empty([lat_dims, lon_dims], dtype=\"float32\")\n",
    "\n",
    "for i in range(len(lons)):\n",
    "    lon_idx = int((lons[i] - min_lon) / step)\n",
    "    lat_idx = int((lats[i] - min_lat) / step)\n",
    "    rf_raster[lat_idx][lon_idx] = pred_rsrp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f1b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = rfco_to_best_server_shapes(\n",
    "    spwr_src_raster=rf_raster,\n",
    "    min_lat=min_lat,\n",
    "    min_lon=min_lon,\n",
    "    step=step,\n",
    ")\n",
    "raw_polys = [geometry.shape(shape[0]) for shape in shapes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edbc83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_polys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04066a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors in ABGR order\n",
    "line_style = fastkml.styles.LineStyle(color=\"7FFF3355\", width=1)\n",
    "poly_style = fastkml.styles.PolyStyle(color=\"88FFEEEE\", fill=1, outline=1)\n",
    "styles = fastkml.styles.Style(KML_NS, styles=[line_style, poly_style])\n",
    "\n",
    "ShapesKMLWriter.shape_dict_to_kmz(\n",
    "    {str(k): poly for k, poly in enumerate(raw_polys)},\n",
    "    \"shapes.kmz\",\n",
    "    styles=[styles],\n",
    "    zipped=False,  # write as KML instead of KMZ for Mapbox viz\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b08c216",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rf_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a2ad1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
